# Defaults
defaults:
  - default
  - _self_
  - split/subjects@_here_

# Target
_target_: src.datamodules.datasets.pure.PURE_Dataset
name: PURE_rPPGToolbox

# Keys : useful for referencing in model config
frames: inputs/frames
labels: targets/labels

# Detections
detections: FaceDetector_FaceMeshV2_landmarks.HDF5

# Filenames
filenames:
  video:
    inputs/frames: null
  bvp:
    targets/labels: bvp_rppgtoolbox.HDF5 # USE linear interp to video-length
  detections:
    detections/landmarks: null # default (see above)
  metadata:
    source/sample: null

# Cache
cache: ${oc.env:DATA_ROOT}/PURE/cache/rPPG-Toolbox/${oc.env:MLFLOW_RUN_UUID,"test"}

# Source
# TODO: IF YOU DO ANY SORTED OF FILTERING THEN YOU CANNOT USE CACHING ATM - DETERMINE UNIQUE NAME FOR CACHING!!!!!!
source:
  _target_: src.datamodules.datasources.paths.Paths
  root: ${paths.data_dir}/vital_signs/PURE_default/processed
  regex: "*/"
  process:
    _target_: src.datamodules.datasources.pure.Default_PURE_rPPGToolbox_DataSample_Frames
    detections: ${datamodule.dataset.detections} # assign default detection file
    _partial_: True

# Samples
construct:
  _target_: src.datamodules.datapipes.DataPipe
  operations: 
    construct_dataset_samples: # ALWAYS construct first
      _target_: src.datamodules.datapipes.sample.construct.GenerateFrameSlices
      window: ${model.network.window}
      # start: 5
      stride: null
      # stop: -5
      return_key: samples # Dict[int, SampleAttrs]

# Process
process:
  _target_: src.datamodules.datapipes.DataPipe
  operations: # Appended with model-specific processes 
    prepare:
      _target_: src.datamodules.datapipes.transform.ToPrepared
    to_float: 
      _target_: src.datamodules.datapipes.transform.frames.ToFloat # to [0-1|FP32]
      fkey: inputs/frames
      max_value: 255
    to_tensor:
      _target_: src.datamodules.datapipes.transform.ToTensor # to tensor
